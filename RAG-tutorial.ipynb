{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b85c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd46452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97b87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a text file\n",
    "\n",
    "text_loader = TextLoader(\"./state_of_the_union.txt\")\n",
    "docs = text_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bfdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk/split text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# save vector embeddings in a database\n",
    "db = FAISS.from_documents(documents, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c7be78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\n"
     ]
    }
   ],
   "source": [
    "# find relevant documents\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "relevant_docs = db.similarity_search(query)\n",
    "print(relevant_docs[0].page_content)\n",
    "\n",
    "# Note this is NOT querying a chat model - only finding the relevant info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f2dee63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='Use the following pieces of context to answer the question at the end.\\nIf you don\\'t know the answer, just say that you don\\'t know, don\\'t try to make up an answer.\\nUse three sentences maximum and keep the answer as concise as possible.\\nAlways say \"thanks for asking!\" at the end of the answer.\\n\\n{context}\\n\\nQuestion: {question}\\n\\nHelpful Answer:')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "custom_rag_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ac002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8445d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a PDF\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"./prompt_engineering.pdf\")\n",
    "pdf_pages = pdf_loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d31df303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: TABLE I\n",
      "CLASSIFYING PROMPT PATTERNS\n",
      "Pattern Category Prompt Pattern\n",
      "Input Semantics Meta Language Creation\n",
      "Output Output Automater\n",
      "Customization Persona\n",
      "Visualization Generator\n",
      "Recipe\n",
      "Template\n",
      "Error Identiﬁcation Fact Check List\n",
      "Reﬂection\n",
      "Prompt Question Reﬁnement\n",
      "Improvement Alternative Approaches\n",
      "\n",
      "2: textual statements approach is that it is intentionally int uitive\n",
      "to users. In particular, we expect users will understand how to\n",
      "express and adapt the statements in a contextually appropri ate\n",
      "way for their domain. Moreover, since the underlying ideas o f\n",
      "the prompt are captured, these same ideas \n"
     ]
    }
   ],
   "source": [
    "# retrieve info from documents\n",
    "\n",
    "faiss_index = FAISS.from_documents(pdf_pages, OpenAIEmbeddings())\n",
    "docs = faiss_index.similarity_search(\"What are the different categories of prompts?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "591247e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The different categories of prompts are Input Semantics, Output Customization, Error Identification, Prompt Improvement, Interaction, and Context Control. Each category focuses on different aspects of prompt patterns in the context of conversational LLMs. Thanks for asking!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the different categories of prompts?\"\n",
    "\n",
    "retriever = faiss_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
